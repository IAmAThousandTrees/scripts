I call this magical process a Bit Matrix Transpose, and it should be an instruction. (colour bbr animation 7s) ✔☻
@7s
Not because it deconflicts scatters, (scatter animation clip) [sending data to piles in ram 4s] ✔☻
@11s
 sorts elements (sorting clip) [rearrange 32 elements into order 2s] ✔☻
@13s
 and counts group memberships, (counting clip) [stream of bitmasks coming down, bits separating and clicking counters accross bottom 3s] ✔☻
@14.5
 or because it's exceedingly simple to implement,
 @18s
  being a fixed wiring of bits from input to output, [byte tranpose drawing lines 7s] ✔☻
 @22
 but because it fills a hole in the vector instruction set: [black screen]
 @26
 All other methods of moving data from column to column currently in the instruction set pull information into the column from somewhere else, 
 @35
 but theres no way for a column to specify a destination column where it's data should be sent *to*. [permute pull/lookup table animation 14.5s] ✔☻
 @41
 This fills that hole, permitting a whole lot of things that were hard before, 
 @47
 like reversing a permutation to send data back where it came from. [reverse the permute animation 10s] ✔☻
 @52
 The operation is exceedingly simple: every output element gets one bit from every input element, with its position in each determining where it will go to and reflecting where it has come from.
  				[direct transform animation, highlight one source bit in each element in red, combining into one element, and one whole source element in green spreading out to one bit in each destination element. the bit which is both is yellow 15s] ✔☻
 @1:07
 In Intels inimitable pseudocode that they describe all their instructions with it would look like this: (display the code speech:6.5s timeslot: 12s)
 
x:=input_element_width:{8,16,32,64};
y:=output_element_width:{8,16,32,64};
ops:=x*y;						//operation size: 64 to 512 bits
rep:=register_width/ops;		//repetitions across the register
r:=0;
DO WHILE r<rep:
	be:=0;						//input bit, output element
	DO WHILE be<x:
		eb:=0;					//input element, output bit
		DO WHILE eb<y
			DEST[r*ops + be*y + eb]:=SRC[r*ops + eb*x + be];
			eb++;
		OD
		be++;
	OD
	r++;
OD

@1:17

This unfolds into a family of 10 BMT operations, with represented every pairing of input and output element width, that doesn't exceed the register width when multiplied together (10s), [list the 10 onscreen]
@1:29
 byte to byte, a 64-bit BMT in each qword, and it's own inverse (10s)
@1:36/37
 word to byte, and it's inverse
 byte to word, both 128-bit BMT's (11s)
@1:45/46
 word to word, it's own inverse,
@1:50
 byte to dword, and it's inverse
 dword to byte; all 256-bit BMT's, 
@1:59
 and finally
 word to doubleword, and its inverse
 doubleword to word, both 512-bit BMT's, and
@2:09
 quadword to byte, and its inverse
 byte to quadword, also 512-bit BMT's.
 @2:18
(quick animations of all 10 as their geometry is mentioned. rainbow colors) ✔☻

It can also be useful to define 2 more: [return to the list, add the 2 (3) new ones]
-vpbmtiww		(interleaved word→word) 256-bits x2
-vpbmt2ewd		(2-source even-words→dword) 1024bits /2
-vpbmt2owd		(2-source odd-words→dword) 1024bits /2

@2:22.5
an interleaved word→word operation where the lower 16 bits of each input dword are transposed into the lower 16 bits of each output dword and the upper 16 bits likewise, since this allows a 1-1 transfer of information from one dword table to another. [animated]
@2:42
And I can also imagine a dword→dword operation from 2 input registers split into 2 parts, where 1 gathers the first 16 dword results from the lower half of all 32 input registers and the other gathers upper halves of all 32 input elements into the remaining 16 dword results. [animated]
@3:01.5
But since it isn't an instruction yet, I currently emulate the members of this instruction family with a series of currently available operations. 
					[fade from the magical instruction to code on screen]
@3:12.5
The family members I make most use of are the word to dword and dword to word variants. This is the dword to word process in assembly language:
@3:23.5
The core is the byte-to-byte BMT on the 8 quadwords of the register. [highlight the core]
@3:29
Then before and after that, a byte permute and/or a byte shuffle rearrange the input and output into the right places to achieve the same result as the higher order operations. [highlight the first/last]

; code eqivalent to:
;	vpbmtdw			zmm0, zmm0
; input bits in zmm0
	vpermb			zmm0, zmm20, zmm0		;zmm20 = 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,1,5,9,13....51,55,59,63 (b)(l2r) 1st bytes together, 2nd bytes...
	vpmultishiftqb	zmm1, zmm21, zmm0		;zmm21 = 0x1c140c04342c241c (x8)(qwords). ie swap halves but shift out from center 4 bits first
	vpternlogd		zmm0, zmm22, zmm1, 0xb8	;B?C:A, zmm22 = 0x0f0f0f0ff0f0f0f0 (x8)(qwords). blend nybbles together
	vpmultishiftqb	zmm1, zmm23, zmm0		;zmm23 = 0x2a22362e0a02160e (x8)(qwords). ie swap adjacent words but shift out from center of each pair 2 bits first
	vpternlogd		zmm0, zmm24, zmm1, 0xb8	;B?C:A, zmm24 = 0x3333cccc3333cccc (x8)(qwords). blend bit-pairs together
	vpmultishiftqb	zmm1, zmm25, zmm0		;zmm25 = 0x3137212711170107 (x8)(qwords). ie swap adjacent bytes but shift out from center of each pair 1 bit first
	vpternlogd		zmm0, zmm26, zmm1, 0xb8	;B?C:A, zmm26 = 0x55aa55aa55aa55aa (x8)(qwords). blend bits together
	vpshufb			zmm0, zmm27, zmm0		;zmm27 = 0,8,1,9,2,10,3,11,4,12,5,13,6,14,7,15; (x4)(b)(l2r)

@3:42
put a variable rotate in front to shift bits into column selection positions, then some permutes, and-masks and 2 vpopcnt's below, and you have everything you need for happy scattering of 16 elements into 32 piles. (add the extra code)

	vpsllvd			zmm0, zmm10, zmm31		;zmm10 has the input column bucket selections. zmm31 is just a row of 1s. this generates the selection mask.

	vpermb			zmm0, zmm20, zmm0		;zmm20 = 0,4,8,12,16,20,24,28,32,36,40,44,48,52,56,60,1,5,9,13....51,55,59,63 (b)(l2r) 1st bytes together, 2nd bytes...
	vpmultishiftqb	zmm1, zmm21, zmm0		;zmm21 = 0x1c140c04342c241c (x8)(qw). ie swap halves but shift out from center 4 bits first
	vpternlogd		zmm0, zmm22, zmm1, 0xb8	;B?C:A, zmm22 = 0x0f0f0f0ff0f0f0f0 (x8)(qwords). blend bits together
	vpmultishiftqb	zmm1, zmm23, zmm0		;zmm23 = 0x2a22362e0a02160e (x8)(qw). ie swap adjacent words but shift out from center of each pair 2 bits first
	vpternlogd		zmm0, zmm24, zmm1, 0xb8	;B?C:A, zmm24 = 0x3333cccc3333cccc (x8)(qwords). blend bits together
	vpmultishiftqb	zmm1, zmm25, zmm0		;zmm25 = 0x3137212711170107 (x8)(qw). ie swap adjacent bytes but shift out from center of each pair 1 bit first
	vpternlogd		zmm0, zmm26, zmm1, 0xb8	;B?C:A, zmm26 = 0x55aa55aa55aa55aa (x8)(qwords). blend bits together
	vpshufb			zmm0, zmm27, zmm0		;zmm27 = 0,8,1,9,2,10,3,11,4,12,5,13,6,14,7,15; (x4)(b)(l2r)

	vpermw			zmm1{k7}{z}, zmm10, zmm0 ; pull gathered bucket selections back into selecting columns. k7=0x5555555555555555
	vpandd			zmm1, zmm1, zmm30		;zmm30 = 0,1,3,7,fh,1fh,3fh,7fh,ffh,1ffh,3ffh,7ffh,fffh,1fffh,3fffh,7fffh (dw)(l2r). relevent bits from columns to right.
				  ; ↑↑↑ 					  this is basically the result you'd get from vpconflictd, but after 11 µops not 37.
	vpopcntd		zmm2, zmm1				; = how much increment on this column to avoid overwriting the previous
	vpopcntw		zmm0, zmm0				; = how much increment on the bucket index after the writes are done. you don't get this info from vpconflictd. at all.
	vpmovzxwd		zmm1, ymm0				; spreading the bucket increments from words to dwords
	vpermw			zmm0{k7}{z}, zmm29, zmm0 ; zmm29 = 16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31 (dw)(l2r) spreading the upper half of the bucket increments
	vpermi2d		zmm10, zmm11, zmm12		; zmm11/12 has the actual bucket indexes
	vpaddd			zmm11, zmm11, zmm1		; increment the 1st 16 buckets for next time
	vpaddd			zmm12, zmm12, zmm0		; increment the 2nd 16 buckets for next time
	vpaddd			zmm10, zmm10, zmm2		; increment the data write indexes to non-conflicting values
	kmovd			k1, k0					; k0 = 0xfffffffffffffffff
	vpscatterdd		[r8 + zmm10 * 4]{k1}, zmm9	; data to be scattered in zmm9
@3:56.2 [remove the extra code]
@3:58.7
Swap the first and last instructions with some adjustment of the indexes [change the first and last lines to match new code]

; code for vpbmtwd	zmm0, zmm0
	vpshufb			zmm0, zmm20, zmm10		;zmm20 = 0,2,4,6,8,10,12,14,1,3,5,7,9,11,13,15; (x4)(b)(l2r) 1st bytes from each word in even qwords, 2nd bytes in odd qw
	vpmultishiftqb	zmm1, zmm21, zmm0		;zmm21 = 0x1c140c04342c241c (x8)(qwords). ie swap halves but shift out from center 4 bits as well
	vpternlogd		zmm0, zmm22, zmm1, 0xb8	;B?C:A, zmm22 = 0x0f0f0f0ff0f0f0f0 (x8)(qwords). blend bits together
	vpmultishiftqb	zmm1, zmm23, zmm0		;zmm23 = 0x2a22362e0a02160e (x8)(qwords). ie swap adjacent words but shift out from center of each pair 2 bits as well
	vpternlogd		zmm0, zmm24, zmm1, 0xb8	;B?C:A, zmm24 = 0x3333cccc3333cccc (x8)(qwords). blend bits together
	vpmultishiftqb	zmm1, zmm25, zmm0		;zmm25 = 0x3137212711170107 (x8)(qwords). ie swap adjacent bytes but shift out from center of each pair 1 bit as well
	vpternlogd		zmm0, zmm26, zmm1, 0xb8	;B?C:A, zmm26 = 0x55aa55aa55aa55aa (x8)(qwords). blend bits together
	vpermb			zmm0, zmm27, zmm0		;zmm27 = 0,16,32,48,1,17,33,49,2,18,34,50....15,31,47,63 (b)(l2r) collect bit0 results in dword0, bit1s in dword1 etc. 

@4:02.7
 and you can throw 32 elements into 16 piles instead: [add the surrounding code]

	vmovdqa32		zmm0, zmm30				;zmm30 = 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62 (w)(l2r) 
	vpermi2w		zmm0, zmm10, zmm11		;zmm10/11 have the bucket selections for 32 dwords. pack 32 selections into one register as words.
	vpsllvw			zmm0, zmm0, zmm31		;zmm31 has 32 1s as words. create bucket selection bitmasks.

	vpshufb			zmm0, zmm20, zmm0		; zmm20 =0,2,4,6,8,10,12,14,1,3,5,7,9,11,13,15; (x4)(b)(l2r) 1st bytes from each word in even qwords, 2nd bytes in odd qw
	vpmultishiftqb	zmm1, zmm21, zmm0		; zmm21 = 0x1c140c04342c241c (x8)(qwords). ie swap halves but shift out from center 4 bits as well
	vpternlogd		zmm0, zmm22, zmm1, 0xb8	; B?C:A, zmm22 = 0x0f0f0f0ff0f0f0f0 (x8)(qw). blend bits together
	vpmultishiftqb	zmm1, zmm23, zmm0		; zmm23 = 0x2a22362e0a02160e (x8)(qwords). ie swap adjacent words but shift out from center of each pair 2 bits as well
	vpternlogd		zmm0, zmm24, zmm1, 0xb8	; B?C:A, zmm24 = 0x3333cccc3333cccc (x8)(qw). blend bits together
	vpmultishiftqb	zmm1, zmm25, zmm0		; zmm25 = 0x3137212711170107 (x8)(qwords). ie swap adjacent bytes but shift out from center of each pair 1 bit as well
	vpternlogd		zmm0, zmm26, zmm1, 0xb8	; B?C:A, zmm26 = 0x55aa55aa55aa55aa (x8)(qw). blend bits together
	vpermb			zmm0, zmm27, zmm0		; zmm27 = 0,16,32,48,1,17,33,49,2,18,34,50....15,31,47,63 (b)(l2r) collect bit0 results in dword0, bit1s in dword1 etc. 

	vpermd			zmm1, zmm10, zmm0		; pull gathered bucket selection bits back into selecting columns. now everyone knows who they're sharing a bucket with
	vpermd			zmm2, zmm11, zmm0		; pull gathered bucket selection bits back into selecting columns. :)
	vpandd			zmm1, zmm1, zmm29		; zmm29 = 0,1,3,7,fh,1fh,3fh,7fh,ffh,1ffh,3ffh,7ffh,fffh,1fffh,3fffh,7fffh (dw)(l2r) filter off leftward column bits
	vpandd			zmm2, zmm2, zmm28		; zmm28 = ffffh,1ffffh,3ffffh,7ffffh,fffffh,1fffffh,3fffffh,7fffffh,ffffffh,1ffffffh,3ffffffh,7ffffffh,fffffffh....
				;	↑↑↑	*********************this is basically the result from 2 vpconflictd instructions, except they're also deconflicting between the two as well 
	vpopcntd		zmm0, zmm0				; but you don't get this result from vpconflictd at all: the increments for the buckets themselves
	vpopcntd		zmm1, zmm1				; first 16 column increments
	vpopcntd		zmm2, zmm2				; second 16 column increments
	vpermd			zmm10, zmm10, zmm12		; zmm12 has the current bucket indexes. select them to the 1st 16 data columns
	vpermd			zmm11, zmm11, zmm12		; zmm12 has the current bucket indexes. select them to the 2nd 16 data columns
	vpaddd			zmm12, zmm12, zmm0		; increment the buckets
	vpaddd			zmm10, zmm10, zmm1		; deconflict the 1st 16 scatter indexes
	vpaddd			zmm11, zmm11, zmm2		; deconflict the 2nd 16 scatter indexes
											; 10p5, 4p0, 8p05, 22µops total
	kmovw			k1, k0					; k0 = 0xffffffffffffffff
	vpscatterdd		[r8 + zmm10 * 4]{k1}, zmm8	; zmm8 has data to be scattered
	kmovw			k1, k0
	vpscatterdd		[r8 + zmm11 * 4]{k1}, zmm9	; zmm9 has data to be scattered
@4.06
[remove the surrounding code and code comments and shrink into the corner, introduce words before rearranging and zooming]
@4:08
the first line rearranges bytes in each 16-byte lane so that the low bytes from each word are all in the first quadword and the high bytes are in the second quadword. (shuffle animation)
@4:20.5
the second & third lines combined replace the upper half of the lower 4 bytes of each quadword with the lower half of the second 4 bytes and the lower half of the second 4 bytes of each quadword with the upper half of the first 4 bytes. (multishift1 and ternlog1 animations)
@4:36.4
the 4th & 5th lines repeat this at the dword/nybble level, swapping the upper half of each nybble of the lower half of the dword with the lower half of each nybble of the upper half of the dword. (multishift2 and ternlog2 animations)
@4:50
The 6th & 7th lines repeat this again with words and bit-pairs. (multishift3 and ternlog3 animations)
@4:57.7
this results in each byte of each lane containing the result-byte-numbered bit from each of the 8 input words in that lane. 
@5:07.6
This would be the end result for vpbmtwb, 
@5:12.5
but then we use a byte permute to bring the byte results from all the lanes together in dwords giving the completed result we want. [permute animation]
@5:22.5
For several examples of using bit matrix transposes see >THIS< video... (avx512isawesome.txt) 
@5:28.5
but a summary of uses I have found so far would be: [list onscreen, highlight each as brackets spoken not on screen]
@5:33
- scatter deconflict	(for scatter deconflict, where it generates a table of index increments for the index source tables as well as for the selected column scatter index table in just 13 µops)
							[show code, highlight the bmt and the instructions using it for scatter deconflict in separate colours]
@5:45.8
- per-bit data bit-counting	(can be used for the pre-radix-sort element counting, also for counting for multiple unrelated sort stages in a single pass, and for multi-group membership counting as well) [show a register of bitmasks, bmt it, popcnt it, accumulate to another register, repeat]
@5:58.2
- reversing a permute table (with the same most-significant-element overwrite priority seen in scatter) [show reverse-permute animation]
@6:07.8
- rapid ranking of vector elements	(use 50% comparison ranking by rotation, bmt away results back to home columns)
					[show register of values, rotate -1 (recirculating values are -0), compare, gather result bits, repeat x7 then shift, bmt, popcnt, to get 0-15.]
@6:19.1
- rapid sorting of vector elements	(then a reverse permute based on the rankings - combined about half the time of a min-max bitonic sort, and creates a permute table that can be applied not only to the original elements being sorted but to any associated data, or even hundreds of times to apply the "sort" to whole datasets)
							[convert to bits, bbr, convert back to numbers, apply permutation to original values showing it is now sorted]
@6:42.3
once the original bits are separated into elements by a BMT, anything that could be applied to element reordering can now be applied to bits, before returning them to their original elements with the reverse BMT.
@6:55.9
A permute becomes an arbitrary bit reordering, [masks: bbr, permute elements, bbr, keep masks visible and show bits moving while the permute happens]
@6:59.5
 vpexpand becomes a paralell-bits-deposit, [masks: bbr, show k-mask binary, expand, bbr ↑↑↑]
@7:03.0
 and compress becomes a parralel-bits-extract. [masks: bbr, show k-mask binary, compress, bbr]
@7:08
This method has just 2 flaws:
@7:14
1: it needs 8 zmmreg constants, (10 if you include the filter-mask for generating the de-conflicting increments afterwards and the rack of 1s for creating the selection mask beforehand) [return to the code: highlight the constants registers and the comments of their contents]
@7:26.7
which either have to occupy 1/4 of the register file, which might be at a premium, or have to be reloaded from memory every time occupying read bandwidth, which might be at a premium, and occupying scheduler slots, which might be at a premium. [replace with mem-loading code]
@7:44.4
2: The other flaw is that the multishift instruction latency of 3c gives the whole process a latency of 16c - though if your loop is properly pipeline-friendly that shouldn't be a problem.
@7:58.2
both flaws would dissapear if it were made an instruction. [fade to vpbmtdw zmm0,zmm0]
@8:02.95
